{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-14T16:42:10.848663Z","iopub.execute_input":"2023-10-14T16:42:10.849060Z","iopub.status.idle":"2023-10-14T16:42:11.306936Z","shell.execute_reply.started":"2023-10-14T16:42:10.849032Z","shell.execute_reply":"2023-10-14T16:42:11.305298Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/netflix-movie-rating-dataset/Netflix_Dataset_Movie.csv\n/kaggle/input/netflix-movie-rating-dataset/Netflix_Dataset_Rating.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/netflix-movie-rating-dataset/Netflix_Dataset_Rating.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-10-14T16:42:11.309029Z","iopub.execute_input":"2023-10-14T16:42:11.309592Z","iopub.status.idle":"2023-10-14T16:42:18.436170Z","shell.execute_reply.started":"2023-10-14T16:42:11.309544Z","shell.execute_reply":"2023-10-14T16:42:18.434864Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-10-14T16:42:18.438427Z","iopub.execute_input":"2023-10-14T16:42:18.438819Z","iopub.status.idle":"2023-10-14T16:42:18.465830Z","shell.execute_reply.started":"2023-10-14T16:42:18.438789Z","shell.execute_reply":"2023-10-14T16:42:18.464351Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"          User_ID  Rating  Movie_ID\n0          712664       5         3\n1         1331154       4         3\n2         2632461       3         3\n3           44937       5         3\n4          656399       4         3\n...           ...     ...       ...\n17337453   520675       3      4496\n17337454  1055714       5      4496\n17337455  2643029       4      4496\n17337456  1559566       3      4496\n17337457   293198       3      4496\n\n[17337458 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User_ID</th>\n      <th>Rating</th>\n      <th>Movie_ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>712664</td>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1331154</td>\n      <td>4</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2632461</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>44937</td>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>656399</td>\n      <td>4</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17337453</th>\n      <td>520675</td>\n      <td>3</td>\n      <td>4496</td>\n    </tr>\n    <tr>\n      <th>17337454</th>\n      <td>1055714</td>\n      <td>5</td>\n      <td>4496</td>\n    </tr>\n    <tr>\n      <th>17337455</th>\n      <td>2643029</td>\n      <td>4</td>\n      <td>4496</td>\n    </tr>\n    <tr>\n      <th>17337456</th>\n      <td>1559566</td>\n      <td>3</td>\n      <td>4496</td>\n    </tr>\n    <tr>\n      <th>17337457</th>\n      <td>293198</td>\n      <td>3</td>\n      <td>4496</td>\n    </tr>\n  </tbody>\n</table>\n<p>17337458 rows Ã— 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['Rating'].nunique()","metadata":{"execution":{"iopub.status.busy":"2023-10-14T16:43:19.778241Z","iopub.execute_input":"2023-10-14T16:43:19.778715Z","iopub.status.idle":"2023-10-14T16:43:19.889546Z","shell.execute_reply.started":"2023-10-14T16:43:19.778681Z","shell.execute_reply":"2023-10-14T16:43:19.888262Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"5"},"metadata":{}}]},{"cell_type":"code","source":"from surprise import SVD\nimport numpy as np\nimport surprise\nfrom surprise import Reader, Dataset","metadata":{"execution":{"iopub.status.busy":"2023-10-14T16:43:25.288192Z","iopub.execute_input":"2023-10-14T16:43:25.288623Z","iopub.status.idle":"2023-10-14T16:43:25.294249Z","shell.execute_reply.started":"2023-10-14T16:43:25.288591Z","shell.execute_reply":"2023-10-14T16:43:25.293053Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# It is to specify how to read the data frame.\nreader = Reader(rating_scale=(1,5))\n\n# create the traindata from the data frame\ntrain_data_mf = Dataset.load_from_df(df[['User_ID', 'Movie_ID', 'Rating']], reader)\n\n# build the train set from traindata. \n#It is of dataset format from surprise library\ntrainset = train_data_mf.build_full_trainset()\nsvd = SVD(n_factors=100, biased=True, random_state=15, verbose=True)\nsvd.fit(trainset)","metadata":{"execution":{"iopub.status.busy":"2023-10-14T16:44:02.957455Z","iopub.execute_input":"2023-10-14T16:44:02.957910Z","iopub.status.idle":"2023-10-14T16:51:17.980561Z","shell.execute_reply.started":"2023-10-14T16:44:02.957881Z","shell.execute_reply":"2023-10-14T16:51:17.979814Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Processing epoch 0\nProcessing epoch 1\nProcessing epoch 2\nProcessing epoch 3\nProcessing epoch 4\nProcessing epoch 5\nProcessing epoch 6\nProcessing epoch 7\nProcessing epoch 8\nProcessing epoch 9\nProcessing epoch 10\nProcessing epoch 11\nProcessing epoch 12\nProcessing epoch 13\nProcessing epoch 14\nProcessing epoch 15\nProcessing epoch 16\nProcessing epoch 17\nProcessing epoch 18\nProcessing epoch 19\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<surprise.prediction_algorithms.matrix_factorization.SVD at 0x78de7fd382e0>"},"metadata":{}}]},{"cell_type":"code","source":"#getting predictions of train set\ntrain_preds = svd.test(trainset.build_testset())\ntrain_pred_mf = np.array([pred.est for pred in train_preds])","metadata":{"execution":{"iopub.status.busy":"2023-10-14T16:52:51.388885Z","iopub.execute_input":"2023-10-14T16:52:51.389294Z","iopub.status.idle":"2023-10-14T16:56:33.561931Z","shell.execute_reply.started":"2023-10-14T16:52:51.389264Z","shell.execute_reply":"2023-10-14T16:56:33.560479Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from scipy import sparse\n\n# Creating a sparse matrix\ntrain_sparse_matrix = sparse.csr_matrix((df.Rating.values, (df.User_ID.values, df.Movie_ID.values)))","metadata":{"execution":{"iopub.status.busy":"2023-10-14T16:59:57.115086Z","iopub.execute_input":"2023-10-14T16:59:57.115553Z","iopub.status.idle":"2023-10-14T17:00:00.119888Z","shell.execute_reply.started":"2023-10-14T16:59:57.115509Z","shell.execute_reply":"2023-10-14T17:00:00.118585Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train_averages = dict()\n# get the global average of ratings in our train set.\ntrain_global_average = train_sparse_matrix.sum()/train_sparse_matrix.count_nonzero()\ntrain_averages['global'] = train_global_average\nprint(train_averages)\n\n# get the user averages in dictionary (key: user_id/movie_id, value: avg rating)\ndef get_average_ratings(sparse_matrix, of_users):\n    # average ratings of user/axes\n    ax = 1 if of_users else 0 # 1 - User axes,0 - Movie axes\n    # \".A1\" is for converting Column_Matrix to 1-D numpy array\n    sum_of_ratings = sparse_matrix.sum(axis=ax).A1\n    # Boolean matrix of ratings ( whether a user rated that movie or not)\n    is_rated = sparse_matrix!=0\n    # no of ratings that each user OR movie..\n    no_of_ratings = is_rated.sum(axis=ax).A1\n    # max_user and max_movie ids in sparse matrix\n    u,m = sparse_matrix.shape\n    # create a dictionary of users and their average ratings..\n    average_ratings = { i : sum_of_ratings[i]/no_of_ratings[i] for i in range(u if of_users else m) if no_of_ratings[i] !=0}\n    #return that dictionary of average ratings\n    return average_ratings\n","metadata":{"execution":{"iopub.status.busy":"2023-10-14T17:00:15.682530Z","iopub.execute_input":"2023-10-14T17:00:15.682922Z","iopub.status.idle":"2023-10-14T17:00:15.809880Z","shell.execute_reply.started":"2023-10-14T17:00:15.682883Z","shell.execute_reply":"2023-10-14T17:00:15.808261Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"{'global': 3.590569909383486}\n","output_type":"stream"}]},{"cell_type":"code","source":"train_averages['user'] = get_average_ratings(train_sparse_matrix, of_users=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-14T17:00:20.055300Z","iopub.execute_input":"2023-10-14T17:00:20.055704Z","iopub.status.idle":"2023-10-14T17:00:20.799086Z","shell.execute_reply.started":"2023-10-14T17:00:20.055675Z","shell.execute_reply":"2023-10-14T17:00:20.797432Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"train_averages['movie'] = get_average_ratings(train_sparse_matrix, of_users=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-14T17:00:24.202628Z","iopub.execute_input":"2023-10-14T17:00:24.203024Z","iopub.status.idle":"2023-10-14T17:00:24.455469Z","shell.execute_reply.started":"2023-10-14T17:00:24.202995Z","shell.execute_reply":"2023-10-14T17:00:24.454233Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity","metadata":{"execution":{"iopub.status.busy":"2023-10-14T17:01:37.421510Z","iopub.execute_input":"2023-10-14T17:01:37.421865Z","iopub.status.idle":"2023-10-14T17:01:37.874426Z","shell.execute_reply.started":"2023-10-14T17:01:37.421840Z","shell.execute_reply":"2023-10-14T17:01:37.873271Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# get users, movies and ratings from our samples train sparse matrix\ntrain_users, train_movies, train_ratings = sparse.find(train_sparse_matrix)","metadata":{"execution":{"iopub.status.busy":"2023-10-14T17:18:49.080071Z","iopub.execute_input":"2023-10-14T17:18:49.080513Z","iopub.status.idle":"2023-10-14T17:18:54.755913Z","shell.execute_reply.started":"2023-10-14T17:18:49.080464Z","shell.execute_reply":"2023-10-14T17:18:54.754404Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime","metadata":{"execution":{"iopub.status.busy":"2023-10-14T17:19:53.953956Z","iopub.execute_input":"2023-10-14T17:19:53.955300Z","iopub.status.idle":"2023-10-14T17:19:53.961245Z","shell.execute_reply.started":"2023-10-14T17:19:53.955250Z","shell.execute_reply":"2023-10-14T17:19:53.959846Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"final_data = pd.DataFrame()\ncount = 0\nfor (user, movie, rating)  in zip(train_users, train_movies, train_ratings):\n            st = datetime.now()\n        #     print(user, movie)    \n            #--------------------- Ratings of \"movie\" by similar users of \"user\" ---------------------\n            # compute the similar Users of the \"user\"        \n            user_sim = cosine_similarity(train_sparse_matrix[user], train_sparse_matrix).ravel()\n            top_sim_users = user_sim.argsort()[::-1][1:] # we are ignoring 'The User' from its similar users.\n            # get the ratings of most similar users for this movie\n            top_ratings = train_sparse_matrix[top_sim_users, movie].toarray().ravel()\n            # we will make it's length \"5\" by adding movie averages to .\n            top_sim_users_ratings = list(top_ratings[top_ratings != 0][:5])\n            top_sim_users_ratings.extend([train_averages['movie'][movie]]*(5 - len(top_sim_users_ratings)))\n        #     print(top_sim_users_ratings, end=\" \")    \n\n\n            #--------------------- Ratings by \"user\"  to similar movies of \"movie\" ---------------------\n            # compute the similar movies of the \"movie\"        \n            movie_sim = cosine_similarity(train_sparse_matrix[:,movie].T, train_sparse_matrix.T).ravel()\n            top_sim_movies = movie_sim.argsort()[::-1][1:] # we are ignoring 'The User' from its similar users.\n            # get the ratings of most similar movie rated by this user..\n            top_ratings = train_sparse_matrix[user, top_sim_movies].toarray().ravel()\n            # we will make it's length \"5\" by adding user averages to.\n            top_sim_movies_ratings = list(top_ratings[top_ratings != 0][:5])\n            top_sim_movies_ratings.extend([train_averages['user'][user]]*(5-len(top_sim_movies_ratings))) \n        #     print(top_sim_movies_ratings, end=\" : -- \")\n\n            #-----------------prepare the row to be stores in a file-----------------#\n            row = list()\n            row.append(user)\n            row.append(movie)\n            # Now add the other features to this data...\n            row.append(train_averages['global']) # first feature\n            # next 5 features are similar_users \"movie\" ratings\n            row.extend(top_sim_users_ratings)\n            # next 5 features are \"user\" ratings for similar_movies\n            row.extend(top_sim_movies_ratings)\n            # Avg_user rating\n            row.append(train_averages['user'][user])\n            # Avg_movie rating\n            row.append(train_averages['movie'][movie])\n\n            # finalley, The actual Rating of this user-movie pair...\n            row.append(rating)\n            count = count + 1\n            row_series = pd.Series(row)\n            final_data = pd.concat([final_data, row_series.to_frame().T], ignore_index=True)\n#             final_data = final_data.append([row])\n            print(count)\n\n           \n        \n            if (count)%10000 == 0:\n                # print(','.join(map(str, row)))\n                print(\"Done for {} rows----- {}\".format(count, datetime.now() - start))\n","metadata":{"execution":{"iopub.status.busy":"2023-10-14T17:33:11.299517Z","iopub.execute_input":"2023-10-14T17:33:11.299909Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n170\n171\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n195\n196\n197\n198\n199\n200\n201\n202\n203\n204\n205\n206\n207\n208\n209\n210\n211\n212\n213\n214\n215\n216\n217\n218\n219\n220\n221\n222\n223\n224\n225\n226\n227\n228\n229\n230\n231\n232\n233\n234\n235\n236\n237\n238\n239\n240\n241\n242\n243\n244\n245\n246\n247\n248\n249\n250\n251\n252\n253\n254\n255\n256\n257\n258\n259\n260\n261\n262\n263\n264\n265\n266\n267\n268\n269\n270\n271\n272\n273\n274\n275\n276\n277\n278\n279\n280\n281\n282\n283\n284\n285\n286\n287\n288\n289\n290\n291\n292\n293\n294\n295\n296\n297\n298\n299\n300\n301\n302\n303\n304\n305\n306\n307\n308\n309\n310\n311\n312\n313\n314\n315\n316\n317\n318\n319\n320\n321\n322\n323\n324\n325\n326\n327\n328\n329\n330\n331\n332\n333\n334\n335\n336\n337\n338\n339\n340\n341\n342\n343\n344\n345\n346\n347\n348\n349\n350\n351\n352\n353\n354\n355\n356\n357\n358\n359\n360\n361\n362\n363\n364\n365\n366\n367\n368\n369\n370\n371\n372\n373\n374\n375\n376\n377\n378\n379\n380\n381\n382\n383\n384\n385\n386\n387\n388\n389\n390\n391\n392\n393\n394\n395\n396\n397\n398\n399\n400\n401\n402\n403\n404\n405\n406\n407\n408\n409\n410\n411\n412\n413\n414\n415\n416\n417\n418\n419\n420\n421\n422\n423\n424\n425\n426\n427\n428\n429\n430\n431\n432\n433\n434\n435\n436\n437\n438\n439\n440\n441\n442\n443\n444\n445\n446\n447\n448\n449\n450\n451\n452\n453\n454\n455\n456\n457\n458\n459\n460\n461\n462\n463\n464\n465\n466\n467\n468\n469\n470\n471\n472\n473\n474\n475\n476\n477\n478\n479\n480\n481\n482\n483\n484\n485\n486\n487\n488\n489\n490\n491\n492\n493\n494\n495\n496\n497\n498\n499\n500\n501\n502\n503\n504\n505\n506\n507\n508\n509\n510\n511\n512\n513\n514\n515\n516\n517\n518\n519\n520\n521\n522\n523\n524\n525\n526\n527\n528\n529\n530\n531\n532\n533\n534\n535\n536\n537\n538\n539\n540\n541\n542\n543\n544\n545\n546\n547\n548\n549\n550\n551\n552\n553\n554\n555\n556\n557\n558\n559\n560\n561\n562\n563\n564\n565\n566\n567\n568\n569\n570\n571\n572\n573\n574\n575\n576\n577\n578\n579\n580\n581\n582\n583\n584\n585\n586\n587\n588\n589\n590\n591\n592\n593\n594\n595\n596\n597\n598\n599\n600\n601\n602\n603\n604\n605\n606\n607\n608\n609\n610\n611\n612\n613\n614\n615\n616\n617\n618\n619\n620\n621\n622\n623\n624\n625\n626\n627\n628\n629\n630\n631\n632\n633\n634\n635\n636\n637\n638\n639\n640\n641\n642\n643\n644\n645\n646\n647\n648\n649\n650\n651\n652\n653\n654\n655\n656\n657\n658\n659\n660\n661\n662\n663\n664\n665\n666\n667\n668\n669\n670\n671\n672\n673\n674\n675\n676\n677\n678\n679\n680\n681\n682\n683\n684\n685\n686\n687\n688\n689\n690\n691\n692\n693\n694\n695\n696\n697\n698\n699\n700\n701\n702\n703\n704\n705\n706\n707\n708\n709\n710\n711\n712\n713\n714\n715\n716\n717\n718\n719\n720\n721\n722\n723\n724\n725\n726\n727\n728\n729\n730\n731\n732\n733\n734\n735\n736\n737\n738\n739\n740\n741\n742\n743\n744\n745\n746\n747\n748\n749\n750\n751\n752\n753\n754\n755\n756\n757\n758\n759\n760\n761\n762\n763\n764\n765\n766\n767\n768\n769\n770\n771\n772\n773\n774\n775\n776\n777\n778\n779\n780\n781\n782\n783\n784\n785\n786\n787\n788\n789\n790\n791\n792\n793\n794\n795\n796\n797\n798\n799\n800\n801\n802\n803\n804\n805\n806\n807\n808\n809\n810\n811\n812\n813\n814\n815\n816\n817\n818\n819\n820\n821\n822\n823\n824\n825\n826\n827\n828\n829\n830\n831\n832\n833\n834\n835\n836\n837\n838\n839\n840\n841\n842\n843\n844\n845\n846\n847\n848\n849\n850\n851\n852\n","output_type":"stream"}]},{"cell_type":"code","source":"#random user and movie\nuser = 6\nmovie = 3","metadata":{"execution":{"iopub.status.busy":"2023-10-14T17:10:14.670241Z","iopub.execute_input":"2023-10-14T17:10:14.670981Z","iopub.status.idle":"2023-10-14T17:10:14.675775Z","shell.execute_reply.started":"2023-10-14T17:10:14.670947Z","shell.execute_reply":"2023-10-14T17:10:14.674567Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# compute the similar Users of the \"user\"\nuser_sim = cosine_similarity(train_sparse_matrix[user], train_sparse_matrix).ravel()\ntop_sim_users = user_sim.argsort()[::-1][1:] # we are ignoring 'The User' from its similar users.\n# get the ratings of most similar users for this movie\ntop_ratings = train_sparse_matrix[top_sim_users, movie].toarray().ravel()\n# we will make it's length \"5\" by adding movie averages to\ntop_sim_users_ratings = list(top_ratings[top_ratings != 0][:5])\ntop_sim_users_ratings.extend([train_averages['movie'][movie]]*(5 -len(top_sim_users_ratings)))","metadata":{"execution":{"iopub.status.busy":"2023-10-14T17:10:14.994528Z","iopub.execute_input":"2023-10-14T17:10:14.994907Z","iopub.status.idle":"2023-10-14T17:10:16.134448Z","shell.execute_reply.started":"2023-10-14T17:10:14.994878Z","shell.execute_reply":"2023-10-14T17:10:16.132850Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# compute the similar movies of the \"movie\"\nmovie_sim = cosine_similarity(train_sparse_matrix[:,movie].T,\ntrain_sparse_matrix.T).ravel()\ntop_sim_movies = movie_sim.argsort()[::-1][1:]\n# we are ignoring 'The User' from its similar users.\n# get the ratings of most similar movie rated by this user\ntop_ratings = train_sparse_matrix[user, top_sim_movies].toarray().ravel()\n# we will make it's length \"5\" by adding user averages to\ntop_sim_movies_ratings = list(top_ratings[top_ratings != 0][:5])\ntop_sim_movies_ratings.extend([train_averages['user'][user]]*(5-len(top_sim_movies_ratings)))","metadata":{"execution":{"iopub.status.busy":"2023-10-14T17:10:16.136252Z","iopub.execute_input":"2023-10-14T17:10:16.137647Z","iopub.status.idle":"2023-10-14T17:10:18.344984Z","shell.execute_reply.started":"2023-10-14T17:10:16.137611Z","shell.execute_reply":"2023-10-14T17:10:18.343775Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"top_sim_users_ratings","metadata":{"execution":{"iopub.status.busy":"2023-10-14T17:12:14.269582Z","iopub.execute_input":"2023-10-14T17:12:14.269989Z","iopub.status.idle":"2023-10-14T17:12:14.277369Z","shell.execute_reply.started":"2023-10-14T17:12:14.269960Z","shell.execute_reply":"2023-10-14T17:12:14.275925Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"[2, 4, 2, 2, 4]"},"metadata":{}}]},{"cell_type":"code","source":"top_sim_movies_ratings","metadata":{"execution":{"iopub.status.busy":"2023-10-14T17:12:04.427445Z","iopub.execute_input":"2023-10-14T17:12:04.428051Z","iopub.status.idle":"2023-10-14T17:12:04.435700Z","shell.execute_reply.started":"2023-10-14T17:12:04.428009Z","shell.execute_reply":"2023-10-14T17:12:04.434324Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"[3, 3, 4, 3, 3]"},"metadata":{}}]},{"cell_type":"code","source":"# prepare train data\nx_train = final_data.drop(['user', 'movie','rating'], axis=1)\ny_train = final_data['rating']\n# initialize XGBoost model\nxgb_model = xgb.XGBRegressor(silent=False, n_jobs=13,random_state=15,n_estimators=100)\n# fit the model\nxgb_model.fit(x_train, y_train, eval_metric = 'rmse')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}